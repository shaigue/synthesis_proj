# synthesis project, 2021

## TODO:
- [x] add to `run_tests.py` saving the found loop invariant to a separate file to each benchmark
- [ ] add to `run_tests.py` saving a table of the times for running each benchmark, and the result (found, bad, timed-out),
  also add to table `is_correct`, `is_expressible` properties of the benchmark.
- [ ] add to `README.md` 
    - [ ] instructions on how to run the benchmarks
    - [ ] how to add functions / constants to the grammar
    - [ ] how to add a new benchmark
    - [ ] some selected examples of properties that the tool was able to prove
    - [ ] describe some techniques that where used in the project (especially the nice ones)
- [ ] submit (via moodle?)